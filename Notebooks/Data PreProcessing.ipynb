{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4fcfd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup    #html tags\n",
    "import unidecode                 #accented chars\n",
    "import contractions              #expand contractions\n",
    "import spacy                     #Preprocessing   # !python -m spacy download en_core_web_sm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize #tokenization # nltk.download('punkt')\n",
    "from nltk.corpus import stopwords       #Stopwords  # nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer #Lemmatizing # nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer     #Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483163c",
   "metadata": {},
   "source": [
    "## Read Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06d9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), '..', 'Data','1_Clean.csv')\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e363bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unique designs This book has beautiful photos,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great Book Loved their approach in this book a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Five Stars great</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great Book! Always love the way Eva thinks, an...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Five Stars Nice patterns</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Unique designs This book has beautiful photos,...  positive\n",
       "1  Great Book Loved their approach in this book a...  positive\n",
       "2                                   Five Stars great  positive\n",
       "3  Great Book! Always love the way Eva thinks, an...  positive\n",
       "4                           Five Stars Nice patterns  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "42d7fe18-4240-4df5-90cb-1938e8bf5549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    7400867\n",
       "negative    1870734\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9772020a-ce6d-44f3-97b5-f9eb442c708c",
   "metadata": {},
   "source": [
    "More positive reviews compared to the negative ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd8d44-c176-4f5d-b0f9-35aafbefda15",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "1. Lowercasing - can also use uppercasing\n",
    "2. HTML Tags - removing html tags if review contains any such tags while scrapping the reviews\n",
    "3. Contractions - expanding contractions - don't to do not\n",
    "4. Word to Numbers - Converting words into numbers - One to 1\n",
    "5. Remove Digits - Removing any digits\n",
    "6. Accented Characters - Removing any accented characters - Boutiqué to Boutique\n",
    "7. Special Characters - Removing any non-alphanumeric characters - includes punctuation, special characters or emoticons\n",
    "8. Whitespaces - Removes extra white spaces from whole review after all above updations\n",
    "\n",
    "Can directly use the functions on the reviews to update them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b0e4d822-950f-4b56-9cdd-471a9dde2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercasing(text):\n",
    "    ## changing all words to lowercase\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d145f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    ## Remove any html tags from reviews using BeautifulSoup and lxml parser\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    return soup.get_text(separator=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0188a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):      #https://medium.com/@lukei_3514/dealing-with-contractions-in-nlp-d6174300876b\n",
    "    ## expand contractions and abbrevations like don't to do not\n",
    "    return contractions.fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cfa7d87d-6ce9-45af-94c8-acbc8c948f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_number_dict = {'zero': '0', 'one': '1', 'two': '2',   'three': '3', 'four': '4',\n",
    "                      'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9'}\n",
    "\n",
    "def word_2_number(text):\n",
    "    ## Convert words into numbers like one to 1\n",
    "    text = text.split()\n",
    "    return ' '.join(word_2_number_dict.get(word, word) for word in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "861c5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(text):\n",
    "    return ''.join(word for word in text if not word.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7a74fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_characters(text):\n",
    "    ## remove accented characters from review like Boutiqué or using unicode module\n",
    "    return unidecode.unidecode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d27c6f8-495b-4357-9755-1cfdd1f8f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    ## remove non-alphanumeric (\\w - [a-zA-Z0-9_], \\s - spaces) \n",
    "    return re.sub(r'[^\\w\\s]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13caf4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespaces(text):\n",
    "    ## remove extra whitespaces \n",
    "    return ' '.join(text.strip().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71741909-0926-46d3-9eb2-a4a246e440e2",
   "metadata": {},
   "source": [
    "### Function Summary: Tokenization, Stopword Removal, Stemming, and Lemmatization\n",
    "\n",
    "Functions for both `nltk` and `spacy` use any one\n",
    "1. tokenization\n",
    "2. stopwords removal - ignored (no, nor, not) for preserving meaning of negative comments\n",
    "3. stemming - using PortStemmer()\n",
    "4. lemmatization - using WordNetLemmatizer() or spacy.lemma_\n",
    "\n",
    "If using both stemming and lemmatization for spacy then make sure to uncomment the commented code in the last function (lemmatization if performing stemming and then lemmatization and stemming if performing lemmatization and then stemming) as spacy requires the doc datatype for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1526a9fa-41fd-4146-bc5e-b4f5fd6bdd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokens_nltk(text):\n",
    "    ## Create Tokens using nltk. \n",
    "    # nltk.download('punkt')\n",
    "    return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "347f4c59-5b2f-47ea-922f-c25eedc79bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")  #Spacy pretrained model for English\n",
    "\n",
    "def create_tokens_spacy(text):\n",
    "    # create doc type tokens using spacy\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ea372d16-b94e-43dd-91da-853640765752",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\")) - {'no', 'nor', 'not'}\n",
    "\n",
    "def remove_stopwords_nltk(tokens):\n",
    "    ## removing stopwords using nltk for nltk tokens\n",
    "    # nltk.download('stopwords')\n",
    "    return [token for token in tokens if token not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "77d2bb83-3537-4563-8b29-3a5773bcc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\")) - {'no', 'nor', 'not'}\n",
    "\n",
    "def remove_stopwords_spacy(tokens):\n",
    "    ## removing stopwords using nltk for spacy doc tokens\n",
    "    # nltk.download('stopwords')\n",
    "    return [token for token in tokens if token.text not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "849c2a95-fdc6-4fa3-a6be-58ec8d74c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming_nltk(tokens):\n",
    "    ## Stemming using nltk.PorterStemmer for nltk tokens\n",
    "    return [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "53aba7ed-4982-4cd5-a45d-4a71cc753ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming_spacy(tokens):\n",
    "    ## Stemming using nltk.PorterStemmer for spacy doc tokens\n",
    "    # Uncomment below line only when using both lemmatization and then stemming\n",
    "    # tokens = nlp(' '.join(token for token in tokens))  #creating doc type. if to be used after lemmatizing as .text requires doc datatype\n",
    "    return [stemmer.stem(token.text) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "51bf90fc-3258-441a-b05c-f6d5bb57de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization_nltk(text):\n",
    "    ## Lemmatization using nltk.WordNetLemmatizer\n",
    "    # nltk.download('wordnet')    \n",
    "    return [lemmatizer.lemmatize(token) for token in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "40490875-c09d-49fc-a40b-439b782d23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization_spacy(tokens):\n",
    "    ## Lemmatization using spacy\n",
    "    # Uncomment below line only when using both stemming and then lemmatization \n",
    "    tokens = nlp(' '.join(token for token in tokens))  #creating doc type. if to be used after stemming as .lemma_ requires doc datatype\n",
    "    return [token.lemma_ for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fad07e-1924-4b84-ad13-fcb0b961a77d",
   "metadata": {},
   "source": [
    "## Applying all the Text preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b5a60bb6-1556-4b7f-b6ce-63036cad18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lowercasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6b1824a5-bc13-4693-b778-4512a9a8bdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\AppData\\Local\\Temp\\ipykernel_1360\\3504131360.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'lxml')\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c682cc2b-5f49-414e-915b-1895628d1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7fa62daa-4255-43af-97e7-950d2c9676ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(word_2_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "01b8ff15-2a24-4bdc-845a-e5f27de1ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "64210923-06dc-4cbc-ac97-f8262cbc9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_accented_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b4bdf4d0-6c71-4ecc-934a-b48a1c070db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e1c57a2b-7d2b-4333-be7b-a445fa6293f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_whitespaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef1384-5b5c-4894-83ac-987f46312b41",
   "metadata": {},
   "source": [
    "## Using Spacy for Tokenization, Stopwords removal, Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "13b20efa-460e-4602-ab77-8221f1e267db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    batch['review'] = batch['review'].apply(create_tokens_spacy)\n",
    "    batch['review'] = batch['review'].apply(remove_stopwords_spacy)\n",
    "    batch['review'] = batch['review'].apply(stemming_spacy)\n",
    "    # batch['review'] = batch['review'].apply(lemmatization_spacy)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "faeed859-360d-4286-9426-83223e65af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9262/9262 [31:35:10<00:00, 12.28s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 1000\n",
    "batch_from = 10000\n",
    "batch_to = len(df)\n",
    "\n",
    "tqdm.pandas(desc=\"Processing\")\n",
    "for i in tqdm(range(batch_from, batch_to, batch_size)):\n",
    "    batch = df.iloc[i:i+batch_size].copy()\n",
    "    df.iloc[i:i+batch_size] = process_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3bf3d87a-bcdf-480e-bb1c-66753ec87a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       [great, qualiti, hard, argu, convers, qualiti,...\n",
       "sentiment                                             positive\n",
       "Name: 10000, dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0c229e2d-80f9-4b75-9665-6d054aa01f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lambda words: ' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "197086c6-9633-4527-baad-2c1e26122cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uniqu design book beauti photo good understand...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great book love approach book paperback easi u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star great</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great book alway love way eva think fun design...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>star nice pattern</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  uniqu design book beauti photo good understand...  positive\n",
       "1  great book love approach book paperback easi u...  positive\n",
       "2                                         star great  positive\n",
       "3  great book alway love way eva think fun design...  positive\n",
       "4                                  star nice pattern  positive"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03706c5d-9f0b-4324-ae56-856c2dd55c58",
   "metadata": {},
   "source": [
    "## Saving the PreProcessed data into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "85768c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), '..', 'Data','2_PreProcessed.csv')\n",
    "df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
